{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "007-detection.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNytjRT3AsPr",
        "colab_type": "text"
      },
      "source": [
        "# The Nature Conservancy Fisheries Monitoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qHiQDVcAsPs",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "_uuid": "784aaee522ae53eff2274a388350b1b1dd60649b",
        "id": "HZyetW4gAsPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30sMLrlkMzJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "os.listdir('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cLoZQQgNDph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('/content/gdrive/My Drive/netology_cv/data/fish/train')\n",
        "#os.listdir('./data/fish/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "263db29157d5633d6f9e7340ab5efec72c677b66",
        "id": "hq0e27OhAsPx",
        "colab_type": "text"
      },
      "source": [
        "# Загружаем разметку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "76496f443d36d16b961aeef10b365e3822b06a2b",
        "id": "pFf7dVCyAsPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "from glob import glob\n",
        "\n",
        "# TODO: скачайте данные и сохраните в директорию:\n",
        "TRAIN_PREFIX = '/content/gdrive/My Drive/netology_cv/data/fish/train'\n",
        "#TRAIN_PREFIX = './data/fish/train'\n",
        "\n",
        "def load_boxes():\n",
        "    boxes = dict()\n",
        "    #for path in glob('./data/fish/boxes/*.json'):\n",
        "    for path in glob('/content/gdrive/My Drive/netology_cv/data/fish/boxes/*.json'):\n",
        "        label = os.path.basename(path).split('_', 1)[0]\n",
        "        with open(path) as src:\n",
        "            boxes[label] = json.load(src)\n",
        "            for annotation in boxes[label]:\n",
        "                basename = os.path.basename(annotation['filename'])\n",
        "                annotation['filename'] = os.path.join(TRAIN_PREFIX, label.upper(), basename)\n",
        "            for annotation in boxes[label]:\n",
        "                for rect in annotation['annotations']:\n",
        "                    rect['x'] += rect['width'] / 2\n",
        "                    rect['y'] += rect['height'] / 2\n",
        "    return boxes\n",
        "\n",
        "def draw_boxes(annotation, rectangles=None, image_size=None):\n",
        "    \n",
        "    def _draw(img, rectangles, scale_x, scale_y, color=(0, 255, 0)):\n",
        "        for rect in rectangles:\n",
        "            pt1 = (int((rect['x'] - rect['width'] / 2) * scale_x),\n",
        "                   int((rect['y'] - rect['height'] / 2) * scale_y))\n",
        "            pt2 = (int((rect['x'] + rect['width'] / 2) * scale_x),\n",
        "                   int((rect['y'] + rect['height'] / 2) * scale_y))\n",
        "            img = cv2.rectangle(img.copy(), pt1, pt2, \n",
        "                                color=color, thickness=4)\n",
        "        return img\n",
        "    \n",
        "    scale_x, scale_y = 1., 1.\n",
        "    \n",
        "    img = cv2.imread(annotation['filename'], cv2.IMREAD_COLOR)[...,::-1]\n",
        "    if image_size is not None:\n",
        "        scale_x = 1. * image_size[0] / img.shape[1]\n",
        "        scale_y = 1. * image_size[1] / img.shape[0]\n",
        "        img = cv2.resize(img, image_size)\n",
        "        \n",
        "    img = _draw(img, annotation['annotations'], scale_x, scale_y)\n",
        "    \n",
        "    if rectangles is not None:\n",
        "        img = _draw(img, rectangles, 1., 1., (255, 0, 0))\n",
        "\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AoiVfGIAsP0",
        "colab_type": "text"
      },
      "source": [
        "### Визуализируем разметку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAc9kyAoAsP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boxes = load_boxes()  # разметка детекций"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjUdf1wIAsP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame([(k, len(v)) for k, v in boxes.items()],\n",
        "             columns=['class', 'count'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "bb49d388931db2cbd5d8f08b9104299ca90a8c5a",
        "id": "IS8e9tY1AsP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(6, 6), dpi=120)\n",
        "img = draw_boxes(boxes['lag'][17])\n",
        "plt.imshow(img)\n",
        "plt.title('{}x{}'.format(*img.shape));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0caa7502a0deb8e5e18773b6d2be8ed2f8d0dd4f",
        "id": "6mqT0kj0AsP_",
        "colab_type": "text"
      },
      "source": [
        "### Распределение размеров разметки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8db3e3e9aa63c1216d3a1f13526d74ab3abe31a8",
        "id": "GMnCjqiNAsP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "annotations = sum([box['annotations']\n",
        "                  for box in sum(boxes.values(), [])], [])\n",
        "\n",
        "widths = [rect['width'] for rect in annotations]\n",
        "heights = [rect['height'] for rect in annotations]\n",
        "\n",
        "plt.hist(widths)\n",
        "plt.hist(heights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ac4e46072546760703354bd43fa09c5d6bd69fb9",
        "id": "jpAVN6bLAsQG",
        "colab_type": "text"
      },
      "source": [
        "# Сетка якорей (anchor grid)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9d267722da49aad29f4bd4b625473295c3293e5f",
        "id": "BJe4h89hAsQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FEATURE_SHAPE = (feature_tensor.shape[1],\n",
        "                 feature_tensor.shape[2])\n",
        "\n",
        "GRID_STEP_H = IMG_HEIGHT / FEATURE_SHAPE[0]\n",
        "GRID_STEP_W = IMG_WIDTH / FEATURE_SHAPE[1]\n",
        "\n",
        "ANCHOR_WIDTH = 150.\n",
        "ANCHOR_HEIGHT = 150. \n",
        "\n",
        "ANCHOR_CENTERS = np.mgrid[GRID_STEP_H/2:IMG_HEIGHT:GRID_STEP_H,\n",
        "                          GRID_STEP_W/2:IMG_WIDTH:GRID_STEP_W]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "Kz16bMWgAsQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iou(rect, x_scale, y_scale, anchor_x, anchor_y,\n",
        "        anchor_w=ANCHOR_WIDTH, anchor_h=ANCHOR_HEIGHT):\n",
        "    \n",
        "    rect_x1 = (rect['x'] - rect['width'] / 2) * x_scale\n",
        "    rect_x2 = (rect['x'] + rect['width'] / 2) * x_scale\n",
        "    \n",
        "    rect_y1 = (rect['y'] - rect['height'] / 2) * y_scale\n",
        "    rect_y2 = (rect['y'] + rect['height'] / 2) * y_scale\n",
        "    \n",
        "    anch_x1, anch_x2 = anchor_x - anchor_w / 2, anchor_x + anchor_w / 2\n",
        "    anch_y1, anch_y2 = anchor_y - anchor_h / 2, anchor_y + anchor_h / 2\n",
        "    \n",
        "    dx = (min(rect_x2, anch_x2) - max(rect_x1, anch_x1))\n",
        "    dy = (min(rect_y2, anch_y2) - max(rect_y1, anch_y1))\n",
        "    \n",
        "    intersection = dx * dy if (dx > 0 and dy > 0) else 0.\n",
        "    \n",
        "    anch_square = (anch_x2 - anch_x1) * (anch_y2 - anch_y1)\n",
        "    rect_square = (rect_x2 - rect_x1) * (rect_y2 - rect_y1)\n",
        "    union = anch_square + rect_square - intersection\n",
        "    \n",
        "    return intersection / union\n",
        "\n",
        "def encode_anchors(annotation, img_shape, iou_thr=0.5):\n",
        "    encoded = np.zeros(shape=(FEATURE_SHAPE[0],\n",
        "                              FEATURE_SHAPE[1], 5), dtype=np.float32)\n",
        "    x_scale = 1. * IMG_WIDTH / img_shape[1]\n",
        "    y_scale = 1. * IMG_HEIGHT / img_shape[0]\n",
        "    for rect in annotation['annotations']:\n",
        "        scores = []\n",
        "        for row in range(FEATURE_SHAPE[0]):\n",
        "            for col in range(FEATURE_SHAPE[1]):\n",
        "                anchor_x = ANCHOR_CENTERS[1, row, col]\n",
        "                anchor_y = ANCHOR_CENTERS[0, row, col]\n",
        "                score = iou(rect, x_scale, y_scale, anchor_x, anchor_y)\n",
        "                scores.append((score, anchor_x, anchor_y, row, col))\n",
        "        \n",
        "        scores = sorted(scores, reverse=True)\n",
        "        if scores[0][0] < iou_thr:\n",
        "            scores = [scores[0]]  # default anchor\n",
        "        else:\n",
        "            scores = [e for e in scores if e[0] > iou_thr]\n",
        "\n",
        "        for score, anchor_x, anchor_y, row, col in scores:\n",
        "            dx = (anchor_x - rect['x'] * x_scale) / ANCHOR_WIDTH\n",
        "            dy = (anchor_y - rect['y'] * y_scale) / ANCHOR_HEIGHT\n",
        "            dw = (ANCHOR_WIDTH - rect['width'] * x_scale) / ANCHOR_WIDTH\n",
        "            dh = (ANCHOR_HEIGHT - rect['height'] * y_scale) / ANCHOR_HEIGHT\n",
        "            encoded[row, col] = [1., dx, dy, dw, dh]\n",
        "            \n",
        "    return encoded\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def decode_prediction(prediction, conf_thr=0.1):\n",
        "    rectangles = []\n",
        "    for row in range(FEATURE_SHAPE[0]):\n",
        "        for col in range(FEATURE_SHAPE[1]):\n",
        "            logit, dx, dy, dw, dh = prediction[row, col]\n",
        "            conf = _sigmoid(logit)\n",
        "            if conf > conf_thr:\n",
        "                anchor_x = ANCHOR_CENTERS[1, row, col]\n",
        "                anchor_y = ANCHOR_CENTERS[0, row, col]\n",
        "                rectangles.append({'x': anchor_x - dx * ANCHOR_WIDTH,\n",
        "                                   'y': anchor_y - dy * ANCHOR_HEIGHT,\n",
        "                                   'width': ANCHOR_WIDTH - dw * ANCHOR_WIDTH,\n",
        "                                   'height': ANCHOR_HEIGHT - dh * ANCHOR_HEIGHT,\n",
        "                                   'conf': conf})\n",
        "    return rectangles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDvvHUQmAsQM",
        "colab_type": "text"
      },
      "source": [
        "### Валидация encoding-а и decoding-а"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "-bmwPm_vAsQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example = boxes['alb'][175]\n",
        "\n",
        "encoded = encode_anchors(example, (IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "decoded = decode_prediction(encoded, conf_thr=0.5)\n",
        "decoded = sorted(decoded, key = lambda e: -e['conf'])\n",
        "\n",
        "plt.figure(figsize=(6, 6), dpi=120)\n",
        "plt.imshow(draw_boxes(example, decoded[:10]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "69b77cba0531fd1ed1c2634e929bee24ac068f7a",
        "id": "hozHxjnzAsQQ",
        "colab_type": "text"
      },
      "source": [
        "## Функция потерь"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "52a6271f7fabac76acec4013093bc35a7f1dc335",
        "id": "D5b5Tmz4AsQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K = tf.keras.backend\n",
        "\n",
        "def confidence_loss(y_true, y_pred):\n",
        "    conf_loss = K.binary_crossentropy(y_true[..., 0], \n",
        "                                      y_pred[..., 0],\n",
        "                                      from_logits=True)\n",
        "    return conf_loss\n",
        "\n",
        "def smooth_l1(y_true, y_pred):\n",
        "    abs_loss = K.abs(y_true[..., 1:] - y_pred[..., 1:])\n",
        "    square_loss = 0.5 * K.square(y_true[..., 1:] - y_pred[..., 1:])\n",
        "    mask = K.cast(K.greater(abs_loss, 1.), 'float32')\n",
        "    total_loss = (abs_loss - 0.5) * mask + 0.5 * square_loss * (1. - mask)\n",
        "    return K.sum(total_loss, axis=-1)\n",
        "\n",
        "def total_loss(y_true, y_pred, neg_pos_ratio=3):\n",
        "    batch_size = K.shape(y_true)[0]\n",
        "    \n",
        "    # TODO: добавьте функцию потерь для классификации детекции\n",
        "    \n",
        "    y_true = K.reshape(y_true, (batch_size, -1, 5))\n",
        "    y_pred = K.reshape(y_pred, (batch_size, -1, 5))\n",
        "\n",
        "    # confidence loss\n",
        "    conf_loss = confidence_loss(y_true, y_pred)\n",
        "    \n",
        "    # smooth l1 loss\n",
        "    loc_loss = smooth_l1(y_true, y_pred)\n",
        "    \n",
        "    # positive examples loss\n",
        "    pos_conf_loss = K.sum(conf_loss * y_true[..., 0], axis=-1)\n",
        "    pos_loc_loss = K.sum(loc_loss * y_true[..., 0], axis=-1)\n",
        "    \n",
        "    # negative examples loss\n",
        "    anchors = K.shape(y_true)[1]\n",
        "    num_pos = K.sum(y_true[..., 0], axis=-1)\n",
        "    num_pos_avg = K.mean(num_pos)\n",
        "    num_neg = K.min([neg_pos_ratio * (num_pos_avg) + 1., K.cast(anchors, 'float32')])\n",
        "    \n",
        "    # hard negative mining\n",
        "    neg_conf_loss, _ = tf.nn.top_k(conf_loss * (1. - y_true[..., 0]),\n",
        "                                   k=K.cast(num_neg, 'int32'))\n",
        "\n",
        "    neg_conf_loss = K.sum(neg_conf_loss, axis=-1)\n",
        "    \n",
        "    # total conf loss\n",
        "    total_conf_loss = (neg_conf_loss + pos_conf_loss) / (num_neg + num_pos + 1e-32)\n",
        "    loc_loss = pos_loc_loss / (num_pos + 1e-32)\n",
        "    \n",
        "    return total_conf_loss + 0.5 * loc_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I5kPhRQAsQU",
        "colab_type": "text"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv3YvHB8AsQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_img(path, target_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
        "    img = cv2.imread(path, cv2.IMREAD_COLOR)[...,::-1]\n",
        "    img_shape = img.shape\n",
        "    img_resized = cv2.resize(img, target_size)\n",
        "    return img_shape, keras.applications.vgg16.preprocess_input(img_resized.astype(np.float32))\n",
        "\n",
        "def data_generator(boxes, batch_size=32):\n",
        "    boxes = sum(boxes.values(), [])\n",
        "    while True:\n",
        "        random.shuffle(boxes)\n",
        "        for i in range(len(boxes)//batch_size):\n",
        "            X, y = [], []\n",
        "            for j in range(i*batch_size,(i+1)*batch_size):\n",
        "                img_shape, img = load_img(boxes[j]['filename'])\n",
        "                # TODO: добавьте one-hot encoding в разметку для классов\n",
        "                y.append(encode_anchors(boxes[j], img_shape))\n",
        "                X.append(img)\n",
        "            yield np.array(X), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b01ffd790e6e7a81bfee104faa4bfa84ad7597c8",
        "id": "tjjN14vMAsQD",
        "colab_type": "text"
      },
      "source": [
        "# Экстрактор признаков"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f3e6d68bd5e0c8a97319185f25a3b25673482606",
        "id": "Z6Ka3IBKAsQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_HEIGHT = 750\n",
        "IMG_WIDTH = 1200\n",
        "\n",
        "features = keras.applications.vgg16.VGG16(include_top=False,\n",
        "                                          weights='imagenet',\n",
        "                                          input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "feature_tensor = features.layers[-1].output\n",
        "\n",
        "# дообучаем последние 5 слоев\n",
        "for layer in features.layers[:-5]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkm-x3NCAsQY",
        "colab_type": "text"
      },
      "source": [
        "## Добавляем выход детектора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a8904e155a9d956eecccd59a9b104bcfd20c44e1",
        "id": "pYeehM0FAsQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = keras.layers.BatchNormalization()(feature_tensor)\n",
        "\n",
        "# TODO: добавьте выходы для классификации детекции\n",
        "output = keras.layers.Conv2D(5,\n",
        "                             kernel_size=(1, 1), \n",
        "                             activation='linear',\n",
        "                             kernel_regularizer='l2')(output)\n",
        "\n",
        "model = keras.models.Model(inputs=features.inputs, outputs=output)\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtGlS_66AsQb",
        "colab_type": "text"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jApLHMcrAsQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = keras.optimizers.Adam(lr=3e-4, decay=1e-6)\n",
        "model.compile(optimizer=adam, \n",
        "              loss=total_loss,\n",
        "              metrics= [confidence_loss]\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKiQEfMMQmR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#определим новый генератор для проверки работоспособности сети,\n",
        "# в котором загрузим всего 100 изображений\n",
        "def data_generator_(boxes, batch_size=32):\n",
        "    boxes = sum(boxes.values(), [])\n",
        "    while True:\n",
        "        random.shuffle(boxes)\n",
        "        for i in range(int(100/batch_size)):\n",
        "            X, y = [], []\n",
        "            for j in range(i*batch_size,(i+1)*batch_size):\n",
        "                img_shape, img = load_img(boxes[j]['filename'])\n",
        "                \n",
        "                y.append(encode_anchors(boxes[j], img_shape))\n",
        "                X.append(img)\n",
        "            yield np.array(X), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "88d52a3e5e2f887dcf4cb295c62c3820c97f0db9",
        "scrolled": false,
        "id": "msSEF2cqAsQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = data_generator_(boxes, batch_size=5)\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    'weights.{epoch:02d}-{loss:.3f}.hdf5',\n",
        "    monitor='loss',\n",
        "    verbose=1,  \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='auto')\n",
        "\n",
        "model.fit_generator(generator=gen, \n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    epochs=5,\n",
        "                    callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqwXjd7XAsQh",
        "colab_type": "text"
      },
      "source": [
        "## Результат работы детектора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6d6d87b271aad9b6f5135870c464f613fce3a31c",
        "id": "hM7_dMH7AsQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example = boxes['lag'][60]\n",
        "\n",
        "_, sample_img = load_img(example['filename'])\n",
        "pred = model.predict(np.array([sample_img,]))[0]\n",
        "\n",
        "decoded = decode_prediction(pred, conf_thr=0.)\n",
        "decoded = sorted(decoded, key=lambda e: -e['conf'])\n",
        "\n",
        "plt.figure(figsize=(6, 6), dpi=120)\n",
        "img = draw_boxes(example, decoded[:3], (IMG_WIDTH, IMG_HEIGHT))\n",
        "plt.imshow(img)\n",
        "plt.title('{}x{}'.format(*img.shape));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xb0fTPNZ5_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#убедимся, что всё работает\n",
        "plt.figure(figsize=(6, 6), dpi=120)\n",
        "img = draw_boxes(example, decoded[:30], (IMG_WIDTH, IMG_HEIGHT))\n",
        "plt.imshow(img)\n",
        "plt.title('{}x{}'.format(*img.shape));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28Bj4UNoaZYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhSGyVGkAsQk",
        "colab_type": "text"
      },
      "source": [
        "## Агрегация результатов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zGiq_xbAsQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: предскажите класс рыбы для фотографии из тестовой выборки\n",
        "#\n",
        "# Подготовьте файл с предсказаниями вероятностей для каждой фотографии:\n",
        "# image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\n",
        "# img_00001.jpg,1,0,0,0,0,...,0\n",
        "# img_00002.jpg,0.3,0.1,0.6,0,...,0"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}